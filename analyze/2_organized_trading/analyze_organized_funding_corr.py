# -*- coding: utf-8 -*-
"""FundingFee_예시코드_조윤서.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y998WRwumDUGx_sz57KAe8Gqx4287kRX
"""

!pip3 install pandas
!pip3 install duckdb
!pip3 install openpyxl

import pandas as pd

Reward = pd.read_excel("problem_data_final.xlsx", sheet_name="Reward")
print(Reward.shape)          # (행, 열)
print(Reward.columns)        # 컬럼 이름
print(Reward.info())         # 데이터 타입
print(Reward.describe())     # 요약 통계 (평균, 표준편차, 최솟값 등)
print(Reward.isnull().sum()) # 결측치 개수

import pandas as pd

Funding = pd.read_excel("problem_data_final.xlsx", sheet_name="Funding")
print(Funding.shape)          # (행, 열)
print(Funding.columns)        # 컬럼 이름
print(Funding.info())         # 데이터 타입
print(Funding.describe())     # 요약 통계 (평균, 표준편차, 최솟값 등)
print(Funding.isnull().sum()) # 결측치 개수

import pandas as pd

Trade = pd.read_excel("problem_data_final.xlsx", sheet_name="Trade")
print(Trade.shape)          # (행, 열)
print(Trade.columns)        # 컬럼 이름
print(Trade.info())         # 데이터 타입
print(Trade.describe())     # 요약 통계 (평균, 표준편차, 최솟값 등)
print(Trade.isnull().sum()) # 결측치 개수

import pandas as pd

IP = pd.read_excel("problem_data_final.xlsx", sheet_name="IP")
print(IP.shape)          # (행, 열)
print(IP.columns)        # 컬럼 이름
print(IP.info())         # 데이터 타입
print(IP.describe())     # 요약 통계 (평균, 표준편차, 최솟값 등)
print(IP.isnull().sum()) # 결측치 개수

import pandas as pd

Spec = pd.read_excel("problem_data_final.xlsx", sheet_name="Spec")
print(Spec.shape)          # (행, 열)
print(Spec.columns)        # 컬럼 이름
print(Spec.info())         # 데이터 타입
print(Spec.describe())     # 요약 통계 (평균, 표준편차, 최솟값 등)
print(Spec.isnull().sum()) # 결측치 개수

"""# 상관관계 도출
- 각 피쳐 상관관계 뽑기 위해 시트 가공 -> df만들기
- 만들어진 df로 히트맵 -> 상관관계
- 이를 이용해서 가중치 정하기

"""

# Feature 1: Funding fee 절댓값 평균
Funding['funding_fee_abs'] = Funding['funding_fee'].abs()
f1 = Funding.groupby('account_id')['funding_fee_abs'].mean().reset_index()
f1.columns = ['account_id', 'funding_fee_abs_mean']

# Feature 2: 평균 holding time
# trade sheet를 가공해서 포지션 OPEN ~ CLOSE 계산
Trade['ts'] = pd.to_datetime(Trade['ts'])

# 같은 account_id + position_id 조합에 대해
# openclose == "OPEN"인 행들의 ts 중 하나
#             "CLOSE"인 행들의 ts 중 하나 를 한줄에 붙여서 OPEN, CLOSE 두 컬럼으로 만들
pos = Trade.pivot_table(
    index=["account_id", "position_id"],
    columns="openclose",
    values="ts",
    aggfunc="first"
).reset_index()

pos['holding_minutes'] = (pos['CLOSE'] - pos['OPEN']).dt.total_seconds() / 60

f2 = pos.groupby('account_id')['holding_minutes'].mean().reset_index()
f2.columns = ['account_id', 'mean_holding_minutes']

# Feature 3: funding timing ratio
# Funding 시트의 ts를 펀딩 시각 +_30분 구간인지 확인
Funding['ts'] = pd.to_datetime(Funding['ts'])
Funding['hour'] = Funding['ts'].dt.hour
funding_hours = [0,4,8,12,16,20]

Funding['is_funding_time'] = Funding['hour'].apply(lambda h: 1 if h in funding_hours else 0)

f3 = Funding.groupby('account_id')['is_funding_time'].mean().reset_index()
f3.columns = ['account_id', 'funding_timing_ratio']

# Feature 4: funding profit ratio
# 전체 수익 = funding_fee + trading PnL
Funding_profit = Funding.groupby('account_id')['funding_fee'].sum().reset_index()
Trade_profit = Trade.groupby('account_id')['amount'].sum().reset_index()

# trading PnL은 Trade에서 계산
df_profit = Funding_profit.merge(Trade_profit, on='account_id', how='left')
df_profit['total_profit'] = df_profit['funding_fee'] + df_profit['amount']
df_profit['funding_profit_ratio'] = df_profit['funding_fee'] / df_profit['total_profit'].replace(0,1)

# 최종 df 만들기
# df: account_id별로
# Funding: 펀딩피 절댓값의 평균,
# Trade: holding_time,
# Funding: funding timing ratio,
# Reward+Trade: net profit -> funding_profit_ratio
df = f1.merge(f2, on='account_id', how='left') \
       .merge(f3, on='account_id', how='left') \
       .merge(df_profit[['account_id','funding_profit_ratio']], on='account_id', how='left')

df_num = df.select_dtypes(include=['float64', 'int64'])
df_num.corr()

import seaborn as sns
import matplotlib.pyplot as plt

# df_features = 유니님의 4개 feature가 들어있는 DF
df_num = df.select_dtypes(include=['float64', 'int64'])
corr_df = df_num[[
    "funding_fee_abs_mean",
    "mean_holding_minutes",
    "funding_timing_ratio",
    "funding_profit_ratio"
]].corr()

plt.figure(figsize=(8, 6))
sns.heatmap(
    corr_df,       # ✔ corr matrix 넣기
    annot=True,
    fmt=".2f",
    cmap="coolwarm",
    linewidths=0.5
)

plt.title("Correlation Heatmap of Funding Hunter Features")
plt.show()

df_corr = df[['funding_fee_abs_mean',
              'mean_holding_minutes',
              'funding_timing_ratio',
              'funding_profit_ratio']].corr()

df['f1'] = df['funding_fee_abs_mean'] / df['funding_fee_abs_mean'].max()
df['f2'] = 1 - df['mean_holding_minutes'] / df['mean_holding_minutes'].max()
df['f3'] = df['funding_timing_ratio']
df['f4'] = df['funding_profit_ratio']

def score(row):
    return 0.35*row['f1'] + 0.25*row['f2'] + 0.25*row['f3'] + 0.15*row['f4']

df['score'] = df.apply(score, axis=1)

df['label'] = df['score'].apply(
    lambda x: 'High' if x > 0.75 else ('Medium' if x > 0.50 else 'Normal')
)

# funding_fee_abs (펀딩피 절댓값)
# Funding sheet에서 가져온 funding_fee
funding_fee_abs = Funding.groupby("account_id")["funding_fee"].apply(lambda x: x.abs().mean())

# mean_holding_minutes (평균 보유 시간)
# Trade sheet에서 가져온 ts, position_id, openclose

# 엑셀에서 읽으면 ts가 문자열(object)로 들어옴
Trade["ts"] = pd.to_datetime(Trade["ts"])

# 같은 account_id + position_id 조합에 대해
# openclose == "OPEN"인 행들의 ts 중 하나
#             "CLOSE"인 행들의 ts 중 하나 를 한줄에 붙여서 OPEN, CLOSE 두 컬럼으로 만들
pos = Trade.pivot_table(
    index=["account_id", "position_id"],
    columns="openclose",
    values="ts",
    aggfunc="first"
).reset_index()

pos["holding_minutes"] = (pos["CLOSE"] - pos["OPEN"]).dt.total_seconds() / 60

mean_holding = pos.groupby("account_id")["holding_minutes"].mean()

# funding
def is_funding_window(ts):
    funding_hours = [0, 4, 8, 12, 16, 20]
    return any(abs(ts.hour - h) <= 0.5 for h in funding_hours)

Trade["ts"] = pd.to_datetime(Trade["ts"])
Trade["is_funding_window"] = Trade["ts"].apply(is_funding_window)

funding_timing_ratio = Trade.groupby("account_id")["is_funding_window"].mean() * 100

import seaborn as sns
import matplotlib.pyplot as plt

cols = ['funding_fee', 'fee_rate']

for col in cols:
    plt.figure(figsize=(8,4))
    sns.histplot(df[col], kde=True, bins=50)
    plt.title(f'{col} Distribution')
    plt.show()

for col in cols:
    plt.figure(figsize=(6,2))
    sns.boxplot(x=df[col])
    plt.title(f'{col} Boxplot')
    plt.show()

import pandas as pd
import duckdb as dd
from collections import Counter

Trade = pd.read_excel("problem_data_final.xlsx", sheet_name="Trade")  # 또는 sheet_name 생략 가능
Funding = pd.read_excel("problem_data_final.xlsx", sheet_name="Funding")
Reward = pd.read_excel("problem_data_final.xlsx", sheet_name="Reward")
Ip = pd.read_excel("problem_data_final.xlsx", sheet_name="IP")
Spec = pd.read_excel("problem_data_final.xlsx", sheet_name="Spec")

Funding['ts'] = pd.to_datetime(Funding['ts'])
Trade['ts'] = pd.to_datetime(Trade['ts'])

"""# Funding Hunter"""

funding_query = """
WITH base AS (
    SELECT
        F.account_id,
        F.ts,
        F.fee_rate,
        F.funding_fee,
        LAG(F.fee_rate)  OVER (PARTITION BY F.account_id ORDER BY F.ts) AS prev_fee_rate,
        LAG(F.ts)        OVER (PARTITION BY F.account_id ORDER BY F.ts) AS prev_ts,
        LAG(F.funding_fee) OVER (PARTITION BY F.account_id ORDER BY F.ts) AS prev_funding_fee
    FROM Funding F
),

-- 1️⃣ 패턴1: 펀딩 직전 반복 진입 & 즉시 청산 패턴
pattern1 AS (
    SELECT
        account_id,
        COUNT(*) AS count_pattern1
    FROM base
    WHERE
        (
            (fee_rate > 0 AND funding_fee > 0) OR   -- 숏 포지션으로 펀딩 수령
            (fee_rate < 0 AND funding_fee > 0)      -- 롱 포지션으로 펀딩 수령
        )
        AND prev_ts IS NOT NULL
        AND (strftime(ts, '%s') - strftime(prev_ts, '%s')) <= 300   -- 5분 이내 연속 포지션
    GROUP BY account_id
),

-- 2️⃣ 패턴2: 포지션 방향이 펀딩률에 100% 종속되는 패턴
pattern2 AS (
    SELECT
        account_id,
        SUM(
            CASE
                WHEN (fee_rate > 0 AND funding_fee > 0) THEN 1   -- 숏 포지션 수령
                WHEN (fee_rate < 0 AND funding_fee > 0) THEN 1   -- 롱 포지션 수령
                ELSE 0
            END
        ) * 1.0
        /
        COUNT(*) AS dependency_ratio
    FROM base
    GROUP BY account_id
),

-- 3️⃣ 패턴3: 펀딩 직전 극단적으로 거래 폭증
pattern3 AS (
    SELECT
        account_id,
        COUNT(*) AS burst_entries
    FROM base
    WHERE
        prev_ts IS NOT NULL
        AND (strftime(ts, '%s') - strftime(prev_ts, '%s')) <= 180  -- 3분 폭증
    GROUP BY account_id
),

-- 4️⃣ 패턴4: 펀딩피 수익이 전체 수익의 대부분
pattern4 AS (
    SELECT
        F.account_id,
        SUM(F.funding_fee) AS funding_profit,
        COALESCE(T.total_rpnl, 0) AS trading_pnl,
        SUM(F.funding_fee) * 1.0 / NULLIF(ABS(T.total_rpnl) + 1e-9, 0) AS funding_ratio
    FROM Funding F
    LEFT JOIN (
        SELECT account_id, SUM(rpnl) AS total_rpnl
        FROM Trade
        GROUP BY account_id
    ) T ON F.account_id = T.account_id
    GROUP BY F.account_id, T.total_rpnl
)

SELECT
    b.account_id,
    COALESCE(p1.count_pattern1, 0) AS pattern1_count,
    COALESCE(p2.dependency_ratio, 0) AS pattern2_ratio,
    COALESCE(p3.burst_entries, 0) AS pattern3_count,
    COALESCE(p4.funding_ratio, 0) AS pattern4_ratio,

    CASE
        WHEN COALESCE(p1.count_pattern1,0) >= 3 THEN 1
        WHEN COALESCE(p2.dependency_ratio,0) >= 0.8 THEN 1
        WHEN COALESCE(p3.burst_entries,0) >= 5 THEN 1
        WHEN COALESCE(p4.funding_ratio,0) >= 0.7 THEN 1
        ELSE 0
    END AS b_funding_hunter

FROM (SELECT DISTINCT account_id FROM Funding) b
LEFT JOIN pattern1 p1 ON b.account_id = p1.account_id
LEFT JOIN pattern2 p2 ON b.account_id = p2.account_id
LEFT JOIN pattern3 p3 ON b.account_id = p3.account_id
LEFT JOIN pattern4 p4 ON b.account_id = p4.account_id;
"""

fund_df = dd.query(funding_query).to_df()
fund_df

funding_hunters=list(set(fund_df[fund_df.b_funding_hunter==1].account_id))
print('Funding Hunter:  ', funding_hunters)

print('유저별 수익 Funding Hunter')
Funding[Funding.account_id.isin(funding_hunters)].groupby('account_id').sum()['funding_fee']*-1

"""# Wash Trading"""

wash_query = """
WITH
position AS (
    SELECT
        account_id,
        position_id,
        MAX(leverage) AS leverage,
         CAST(min(ts) AS TIMESTAMP) as open_ts,
        CAST(max(ts) AS TIMESTAMP) as closing_ts,
        max(symbol) as symbol,
        max(side) as side,
        DATE(max(ts)) as closing_day,
        sum(if(openclose='OPEN',amount,0)) as amount,
        sum(if(openclose='OPEN',-amount,amount)*if(side='LONG',1,-1)) as rpnl
    from Trade
    GROUP BY account_id, position_id
),
joined AS (
    select
        t1.account_id AS account_id1,
        t2.account_id AS account_id2,
        t1.symbol,
        t1.open_ts AS open_ts1,
        t2.open_ts AS open_ts2,
        t1.closing_ts AS closing_ts1,
        t2.closing_ts AS closing_ts2,
        t1.leverage,
        t1.amount AS amount,
        t2.amount AS amount,
        t1.position_id AS position_id1,
        t2.position_id AS position_id2,
        t1.side as side1,
        t2.side as side2,
        t1.rpnl as rpnl1,
        t2.rpnl as rpnl2,

    from
    position t1 inner join position t2
        on
            t1.symbol = t2.symbol
            and  ABS(julian(t1.open_ts) - julian(t2.open_ts)) * 24 * 60 <=2
            and  ABS(julian(t1.closing_ts) - julian(t2.closing_ts)) * 24 * 60 <=2
            and t1.leverage = t2.leverage
            and t1.open_ts <t2.open_ts
            and t1.amount <= 1.02 * t2.amount and t1.amount >= 0.98 * t2.amount
            and GREATEST(t1.open_ts, t2.open_ts) < LEAST(t1.closing_ts, t2.closing_ts)
            and t1.account_id != t2.account_id
            and t1.side != t2.side
            and (t1.rpnl>0 or t2.rpnl>0)
)

SELECT DISTINCT *
FROM joined
ORDER BY symbol, open_ts1;
"""

wash_df=(dd.query(wash_query).to_df())

unique_pairs = set(tuple(sorted([a1, a2])) for a1, a2 in zip(wash_df.account_id1, wash_df.account_id2))

import pandas as pd

# 1️⃣ 각 계정별 rpnl > 0 / < 0 합 계산
rpnl_long = pd.concat([
    wash_df[['account_id1', 'rpnl1']].rename(columns={'account_id1': 'account_id', 'rpnl1': 'rpnl'}),
    wash_df[['account_id2', 'rpnl2']].rename(columns={'account_id2': 'account_id', 'rpnl2': 'rpnl'})
])

rpnl_stats = (
    rpnl_long.groupby('account_id')['rpnl']
    .agg([
        ('rpnl_pos_sum', lambda x: x[x > 0].sum()),
        ('rpnl_neg_sum', lambda x: x[x < 0].sum())
    ])
    .fillna(0)
)

# 2️⃣ reward 합산
reward_sum = Reward.groupby('account_id')['reward_amount'].sum().rename('reward_sum')

# 3️⃣ 병합 후 계정별 net_pnl 계산
account_stats = (
    rpnl_stats.join(reward_sum, how='left').fillna({'reward_sum': 0})
)
account_stats['net_pnl'] = account_stats['rpnl_pos_sum'] + (account_stats['rpnl_neg_sum'] + account_stats['reward_sum']).clip(upper=0)

# 4️⃣ pair별 합산
def sorted_pair(a, b):
    return tuple(sorted([a, b]))

wash_df['pair'] = wash_df.apply(lambda row: sorted_pair(row['account_id1'], row['account_id2']), axis=1)

pair_net_pnl = (
    pd.DataFrame(wash_df['pair'].unique(), columns=['pair'])
    .assign(
        net_pnl1=lambda df: df['pair'].apply(lambda p: account_stats.loc[p[0], 'net_pnl'] if p[0] in account_stats.index else 0),
        net_pnl2=lambda df: df['pair'].apply(lambda p: account_stats.loc[p[1], 'net_pnl'] if p[1] in account_stats.index else 0)
    )
)
pair_net_pnl['pair_net_pnl'] = pair_net_pnl['net_pnl1'] + pair_net_pnl['net_pnl2']

# 5️⃣ 정렬된 결과
pair_net_pnl = pair_net_pnl.sort_values('pair_net_pnl', ascending=False).reset_index(drop=True)
pair_net_pnl

"""# Cooperative Trading"""

cop_query ="""
WITH
position AS (
    SELECT
        account_id,
        position_id,
        MAX(leverage) AS leverage,
         CAST(min(ts) AS TIMESTAMP) as open_ts,
        CAST(max(ts) AS TIMESTAMP) as closing_ts,
        max(symbol) as symbol,
        max(side) as side,
        DATE(max(ts)) as closing_day,
        sum(if(openclose='OPEN',amount,0)) as amount,
        sum(if(openclose='OPEN',-amount,amount)*if(side='LONG',1,-1)) as rpnl
    from Trade
    GROUP BY account_id, position_id
),
joined AS (
    select
        t1.account_id AS account_id1,
        t2.account_id AS account_id2,
        t1.symbol,
        t1.open_ts AS open_ts1,
        t2.open_ts AS open_ts2,
        t1.closing_ts AS closing_ts1,
        t2.closing_ts AS closing_ts2,
        t1.leverage,
        t1.amount AS amount1,
        t2.amount AS amount2,
        t1.position_id AS position_id1,
        t2.position_id AS position_id2,
        t1.side as side1,
        t2.side as side2,
        t1.rpnl as rpnl1,
        t2.rpnl as rpnl2,

    from
    position t1 inner join position t2
        on
            t1.symbol = t2.symbol
            and  ABS(julian(t1.open_ts) - julian(t2.open_ts)) * 24 * 60 <=2
            and  ABS(julian(t1.closing_ts) - julian(t2.closing_ts)) * 24 * 60 <=2
            and t1.open_ts <t2.open_ts
            and GREATEST(t1.open_ts, t2.open_ts) < LEAST(t1.closing_ts, t2.closing_ts)
            and t1.account_id != t2.account_id
            and t1.side = t2.side
            and t1.symbol not in ('BTCUSDT.PERP','ETHUSDT.PERP','SOLUSDT.PERP','XRPUSDT.PERP','BNBUSDT.PERP','DOGEUSDT.PERP')
)

SELECT DISTINCT *
FROM joined
ORDER BY symbol, open_ts1;
"""

cop_df=(dd.query(cop_query).to_df())

unique_pairs = set(tuple(sorted([a1, a2])) for a1, a2 in zip(cop_df.account_id1, cop_df.account_id2))
groups = []

for a, b in unique_pairs:
    # a 또는 b가 이미 포함된 그룹 찾기
    found = []
    for g in groups:
        if a in g or b in g:
            g.update([a, b])
            found.append(g)

    if not found:
        # 아직 속한 그룹이 없으면 새 그룹 생성
        groups.append(set([a, b]))
    elif len(found) > 1:
        # 여러 그룹이 겹치면 병합
        merged = set().union(*found)
        groups = [g for g in groups if g not in found]
        groups.append(merged)

# 출력 (정렬된 리스트로)
connected_groups = [sorted(list(g)) for g in groups]

for i, g in enumerate(connected_groups, 1):
    print(f"Group {i}: {g}")

group_pnls = []

for group in connected_groups:
    group_set = set(group)
    sub = cop_df[
        cop_df['account_id1'].isin(group_set) | cop_df['account_id2'].isin(group_set)
    ]

    # 개별 PnL 합산
    total_pos = sub[['rpnl1', 'rpnl2']].clip(lower=0).sum().sum()
    total_neg = sub[['rpnl1', 'rpnl2']].clip(upper=0).sum().sum()
    total_pnl = total_pos + total_neg

    group_pnls.append({
        'group': group,
        'pnl_positive_sum': total_pos,
        'pnl_negative_sum': total_neg,
        'pnl_total': total_pnl
    })

group_pnls_df = (
    pd.DataFrame(group_pnls)
    .sort_values('pnl_total', ascending=False)
    .reset_index(drop=True)
)

cnts=[]
for i in group_pnls_df['group']:
    cnt = len([kk for kk,vv in Counter(Ip[Ip.account_id.apply(lambda a: a in i)].ip).items() if vv>1])
    cnts.append(cnt)

group_pnls_df['ip_cnt']= cnts
group_pnls_df